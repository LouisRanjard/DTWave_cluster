\documentclass[a4paper]{article}
\usepackage{vmargin}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{array}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{multirow}

\usepackage{Sweave}
\usepackage{vmargin}

\setmarginsrb{1.5cm}{1cm}{1.5cm}{1cm}{1cm}{1cm}{1cm}{1cm}

\usepackage{hyperref}
\hypersetup{colorlinks,%
            citecolor=black,%
            filecolor=black,%
            linkcolor=black,%
            urlcolor=blue}

\usepackage{graphicx}
\usepackage{color}

\sloppy
\definecolor{lightgray}{gray}{0.5}
\setlength{\parindent}{0pt}



\begin{document}

\thispagestyle{empty}
\setkeys{Gin}{width=100pt}
\begin{minipage}{0.6\linewidth}
%\begin{center}
\begin{large}
Bioinformatics Institute\\
The University of Auckland\\
\end{large}
%\end{center}
\end{minipage}


\setkeys{Gin}{width=30pt}
\begin{center} 
\vspace{270 pt}
\begin{Huge}
Tutorial Matlab functions \texttt{dtwave\_cluster}\\
\vspace{2pt}
\hrule
\end{Huge}
\end{center}
\begin{flushright}
\begin{Large}
\textbf{Louis Ranjard - l.ranjard@auckland.ac.nz}\\
\end{Large}
\end{flushright}
\vspace{250pt}
\begin{center}
\today
\end{center}
\vspace{35pt}
\newpage


\section*{Introduction}
This tutorial illustrates the usage of \texttt{dtwave\_cluster} package for the automatic classification of bird song syllables.
Please note that \texttt{dtwave\_cluster} was developed to classify large amount of recordings \cite{ranjard} therefore the small data used in this tutorial does not constitute a representative dataset.
However, this document shows how to use the package to perform a typical short and simple analysis.

\setlength\abovecaptionskip{-12pt}
\section{Data set: Little Barrier Island Song Recordings}
A set of 11 song recordings were collected on Little Barrier Island using a SongMeter equipment (Figure \ref{fig:songs}).
Songs were first manually subdivided into their constitutive syllables and the sound signal of each syllable was saved as an independent WAV file (directory \(data\)).
The song segmentation step can also be performed automatically, especially when analysing large dataset, but this is out of the scope of this tutorial.

The species name and syllable files for each song are as below:
\begin{itemize}
\item 4 saddleback songs
  \begin{itemize}
  \item files 1.wav to 4.wav
  \item files 5.wav to 9.wav
  \item files 25.wav to 31.wav
  \item files 37.wav to 42.wav
  \end{itemize}
\item 5 hihi songs
  \begin{itemize}
  \item file 32.wav
  \item file 33.wav
  \item file 34.wav
  \item file 35.wav
  \item file 36.wav
  \end{itemize}
\item 1 long-tailed cuckoo song
  \begin{itemize}
  \item files 10.wav to 19.wav
  \end{itemize}
\item 1 bellbird song
  \begin{itemize}
  \item files 20.wav to 24.wav
  \end{itemize}
\end{itemize}


\begin{figure}[h!]
\begin{center}
\includegraphics[width=.9\textwidth]{/home/louis/Documents/DTWave/test/Little_Barrier_Island/extracted_songs/all_songs_nocluster.pdf}
\vspace{1cm}
\caption{Spectrograms of recorded songs with syllable boundaries and file names.}
\end{center}
\label{fig:songs}
\end{figure}

\clearpage
\section{Song Classification}
First add the \texttt{dtwave\_cluster} uncompressed directory to your Matlab \texttt{PATH}.
The function \texttt{dtwave\_cluster} can now be called to perform the automatic classification of the syllable recordings.
Several options can be passed to this function.
In particular, we encode the songs with a short time window, 0.02 seconds, and partial overlap, 0.005 seconds, because we are interested in short variation in the signal.
A larger window would be more efficient if for example one is aiming at classifying whole song recordings.
The number of evolving tree classifications is set to 10 and the default values for the other parameters are used.
At the Matlab prompt, type:

\begin{verbatim}
[syllable,~,~,classrep] = dtwave_cluster('./data', 'wintime',0.02,'hoptime',0.005,'nrepeat',10) ;
\end{verbatim}

\color{lightgray}
\begin{verbatim}
****** dtwave_cluter: unsupervised sound classification ******

42 WAV files loaded
Parameters: 4, 0.5, 0.05, 2, 1, 4, 2, 2, 0.95

--------------------- classification tree: 1/10 ---------------------
epoch time -- Neighborhood Size, Mapping precision, Tree size, Leaves number
epoch 1/4 01-04-2014 18:32 -- 1, 10.0715, 41, 31
epoch 2/4 01-04-2014 18:32 -- 2, 10.2637, 41, 31
epoch 3/4 01-04-2014 18:32 -- 2, 10.5012, 44, 33
epoch 4/4 01-04-2014 18:32 -- 1, 9.43704, 71, 51
15 clusters
Davies-Bouldin indice: 5.15243
Classified syllable 1

--------------------- classification tree: 2/10 ---------------------
epoch time -- Neighborhood Size, Mapping precision, Tree size, Leaves number
epoch 1/4 01-04-2014 18:32 -- 1, 9.91937, 41, 31
epoch 2/4 01-04-2014 18:32 -- 2, 9.97057, 44, 33
epoch 3/4 01-04-2014 18:32 -- 2, 9.5719, 68, 49
epoch 4/4 01-04-2014 18:32 -- 1, 9.82024, 95, 67
17 clusters
Davies-Bouldin indice: 60.3539
Classified syllable 1

--------------------- classification tree: 3/10 ---------------------
...
\end{verbatim}
\color{black}

A total of 10 classifications is performed.
For each classification replicate, the data structure \texttt{classrep} contains the cluster number attributed to each syllable recording in column.
For example, it is possible to look at the classifications of the recordings 1 to 10. 

\begin{verbatim}
classrep(1:10,:)
\end{verbatim}

\color{lightgray}
\begin{verbatim}
ans =

     4     1     5     3     9     3     6     1     3     3
    13     4     8    14    11    10     3     9     1     9
    13     4     3    12    10     9     3     9     1     9
     8     4     3    12    10     8     3     9     1     9
     8     4     3    12    10     8     3     9     1     9
     8     4     3    12    10     8     3     9     1     9
     8     4     3    12    10     8     3     9     1     9
     8     4     3    12    10     8     3     9     1     9
     8     4     3    12    10     8     3     9     1     9
    13     4     3    15    10     8     3     9     1     9

\end{verbatim}
\color{black}

It appears that the recordings 4 to 9 are consistently grouped together while the recordings 2, 3 and 10 are frequently grouped in the same cluster too.
On the other hand, the recording 1 is never clustered with the recordings 2 to 10.
This result shows that the syllables 2 to 10 share high acoustic similarity and the syllable 1 is different, indicating that it probably belongs to a different type. 

The data structure \texttt{syllable} contains the file name corresponding to each recording.
Looking at the file names for the recording 1 to 10 allows us to map the recordings back to the original song files.

\begin{verbatim}
fprintf(1,'%s\n',syllable(1:10).filename)
\end{verbatim}

\color{lightgray}
\begin{verbatim}
1.wav
10.wav
11.wav
12.wav
13.wav
14.wav
15.wav
16.wav
17.wav
18.wav
\end{verbatim}
\color{black}

The syllables 2 to 10 (10.wav, 11.wav,..., 18.wav) belongs to the same song recordings showing high consistency between the syllables of this song.

\section{Classification analysis}
The data structure \texttt{classrep} can be used to investigate biological questions related to the song recordings.
These questions can be treated by integrating results over replicates.
For example, one can ask how many syllables are shared between two sets of saddleback songs.
We can answer that question by counting the number of times the syllables of the two different sets of songs are classified together.
Let's consider set 1 as the first two saddleback songs (syllable 1.wav to 9.wav) and the two last saddleback songs (syllables 25.wav to 31.wav and syllables 37.wav to 42.wav).

First, we need to retrieve the indexes of the syllable of each set.

\begin{verbatim}
set1 = find( ismember({syllable.filename},{'1.wav';'2.wav';'3.wav';'4.wav';'9.wav';...
      '37.wav';'38.wav';'39.wav';'40.wav';'41.wav';'42.wav'})==1 ) ;
set2 = find( ismember({syllable.filename},{'5.wav';'6.wav';'7.wav';'8.wav';'25.wav';...
      '26.wav';'27.wav';'28.wav';'29.wav';'30.wav';'31.wav'})==1 ) ;
\end{verbatim}

Then, we compare the cluster indices of the syllable of the two sets in each classification.

\begin{verbatim}
common = zeros(1,10) ;
for n=1:10
  common_syllable = numel( intersect( classrep(set2,n), classrep(set1,n)) ) ;
  unique_syllable = numel( unique( [classrep(set2,n); classrep(set1,n) ]) ) ;
  common(n) = common_syllable/unique_syllable ;
end
mean(common)
\end{verbatim}

\color{lightgray}
\begin{verbatim}
ans =

    0.1615
\end{verbatim}
\color{black}

Therefore, on average the two sets share about 16\% of their syllables.
These results could be compared across sets of songs belonging to different populations for example.

\section{Classification replicates summary}
A way to summarize the classification replicates is to estimate the distances between recordings using the Jaccard distance, i.e. one minus the percentage of clusters that differ.
The distances between recordings can then be represented on a summary dendrogram.

\begin{verbatim}
Z = linkage(classrep,'average','jaccard') ;
dendrogram(Z,50,'Labels',{syllab1.filename},'Orientation','left') ;
\end{verbatim}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=.9\textwidth]{/home/louis/Documents/DTWave/test/Little_Barrier_Island/distance_tree_annotated.pdf}
\caption{Syllable pairwise distances.}
\end{center}
\label{fig:tree}
\end{figure}

Figure \ref{fig:tree} represents the syllable pairwise distances as defined by the classification replicates.
From the dendrogram it clearly appears that the syllables group into clusters.
Each group constitutes a syllable cluster and is refereed to with a letter from \(A\) to \(G\).

It is now possible to encode the songs as a sequence of syllables using the summary dendrogram clusters.
Figure \ref{fig:songs2} shows the song spectrograms with the cluster indicated for each syllable (\(A\) to \(G\)).

\begin{figure}[h!]
\begin{center}
\includegraphics[width=.9\textwidth]{/home/louis/Documents/DTWave/test/Little_Barrier_Island/extracted_songs/all_songs.pdf}
\vspace{1cm}
\caption{Song with encoded syllables following classification replicates summary.}
\end{center}
\label{fig:songs2}
\end{figure}


\clearpage
\section{Classification of the original songs}
directory \(/home/louis/Documents/DTWave/test/Little_Barrier_Island/extracted_songs\)


\clearpage
\section{Classification of a single song syllables}
directory \(/home/louis/Documents/DTWave/test/Little_Barrier_Island/extracted_songs/song.wav\)
>> [syllab1,~,~,classrep,DavBou] = dtwave_cluster('/home/louis/Documents/DTWave/test/Little_Barrier_Island/extracted_songs/splitted_song_wav',...
'wintime',0.01,'hoptime',0.005,'nrepeat',10,'wHamming',1);



\clearpage
\section{Running the standalone application}
Install the Matlab MCR program for your system.
Then \texttt{dtwave\_cluster} can be run witht the command:
./run_dtwave_cluster.sh <mcr_directory> <wav files directory> <argument_list formatted as: 'argument' value>
For example, \\
./run_dtwave_cluster.sh ~/MATLAB/MATLAB_Compiler_Runtime/v81 ~/Documents/Reviews/BehavioralEcology_Apr2014/dtwave_analysis/ 'wintime' 0.05 'hoptime' 0.02

\clearpage
\section{Appendix - dtwave\_cluster options}

\begin{table}[b]
\caption{.
}
\vspace{0.5cm}
\label{tab:dtwaveclusterparam}
\begin{center}
\begin{tabular}{r|c|l}
\hline
Parameters & Description & Default value\\
\hline
\hline
htkconfigdir   &   &  \\
verbose        &   & 0 \\
outputfile     &   & wavdir/dtwave\_cluster.csv \\
wintime        &   &  0.3 \\
hoptime        &   &  0.1... \\
numcep         &   & 13 \\
lifterexp      &   & -22 \\
sumpower       &   & 1 \\
preemph        &   &  0.97 \\
dither         &   & 0 \\
minfreq        &   & 300 \\
maxfreq        &   & 20000 \\
nbands         &   & 26 \\
bwidth         &   & 1.0 \\
dcttype        &   & 3 \\
fbtype         &   &  htkmel \\
usecmp         &   & 0 \\
modelorder     &   & 0 \\
broaden        &   & 0 \\
epoch          &   & 4 \\
LR             &   & [0.5 0.05] \\
NS             &   & [2 1] \\
NC             &   &  [4 2] \\
thexpan        &   &  -1 \\
gama           &   & 0.95 \\
ce             &   &  0 \\
nrepeat        &   &  5 \\
depth          &   &  0  \\
\hline
\end{tabular}
\end{center}
\end{table}


\clearpage
\begin{thebibliography}{9}
   \bibitem{ranjard}
        Ranjard, L. and Ross H.A.
          \emph{Unsupervised bird song syllable classification using evolving neural networks.}
          J Acoust Soc Am. 2008 Jun;123(6):4358-68
\end{thebibliography}


\end{document}

% cd ~/Documents/DTWave/tutorial
% pdflatex tutorial_dtwave_cluster.tex


